#!/usr/bin/env python
#JHK
import numpy as np
from netCDF4 import Dataset
import tensorflow as tf
from tensorflow.keras import Model, datasets, layers, models, backend
from tensorflow import keras
from contextlib import redirect_stdout
import os, sys
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

os.environ["CUDA_DEVICE_ORDER"]="PCI_BUS_ID"
os.environ["CUDA_VISIBLE_DEVICES"]= "gpu_number"

op_train = 'op_training'
op_test  = 'op_testing'
op_gpu   = 'option_gpu'

o_path = 'h_dir/output/exp_name/ENensemble/'

if op_gpu == 'on':
    gpus = tf.config.experimental.list_physical_devices('GPU')
    tf.config.experimental.set_memory_growth(gpus[0], True)


if op_train == 'on':
    
    #------------------------------------------------------------------------
    # load training set
    #------------------------------------------------------------------------
    # input
    f = Dataset('h_dir/input/tr_inp','r')
    tr_x = f.variables['prcp'][:,:,12:67,:]
    f.close()

    # extend (0-360 -> 0-400)
    tr_x = np.append(tr_x, tr_x[:,:,:,:16], axis=3) 
    
    tdim, cdim, ydim, xdim = tr_x.shape

    # axes swap
    tr_x = np.swapaxes(tr_x, 1, 3)
    
    # label
    f = Dataset('h_dir/input/tr_lab','r')
    tr_y = f.variables['agmt'][:,:,0,0]
    f.close()

    #------------------------------------------------------------------------
    # load validation set
    #------------------------------------------------------------------------
    # input
    f = Dataset('h_dir/input/val_inp','r')
    val_x = f.variables['prcp'][:,:,12:67,:]
    f.close()

    # extend (0-360 -> 0-380)
    val_x = np.append(val_x, val_x[:,:,:,:16], axis=3) 

    test_tdim, cdim, ydim, xdim = val_x.shape

    # axes swap
    val_x = np.swapaxes(val_x, 1, 3)

    # label
    f = Dataset('h_dir/input/val_lab','r')
    val_y = f.variables['agmt'][:,:,0,0]
    f.close()

#------------------------------------------------------------------------
# load test set (for evaluation)
#------------------------------------------------------------------------
if op_test == 'on':

    # input
    f = Dataset('h_dir/input/test_inp','r')
    test_x = f.variables['prcp'][:,:,12:67,:]
    f.close()

    # extend (0-360 -> 0-380)
    test_x = np.append(test_x, test_x[:,:,:,:16], axis=3) 

    test_tdim, cdim, ydim, xdim = test_x.shape

    # axes swap
    test_x = np.swapaxes(test_x, 1, 3)

#------------------------------------------------------------------------
# set callbacks
#------------------------------------------------------------------------
callbacks_list = [

  keras.callbacks.EarlyStopping(
    monitor='val_loss',
    mode='min',
    patience=100,
  ),

  keras.callbacks.ModelCheckpoint(
    filepath=o_path+'model.hdf5',
    monitor='val_loss',
    save_best_only=True,
  )
]

#---------------------------------------------------------------------------------------------
def conv_set(X, n_feat, k_size, act, stride=1, reg=None):

    # Convolution
    conv = layers.Conv2D(n_feat, k_size, activation=act, 
                         padding='same', strides=stride,
                         kernel_regularizer=reg, 
                         bias_regularizer=reg,
                         activity_regularizer=reg)(X)
      
    return conv

def dense_set(X, n_feat, act, reg=None):

    # dense
    dense = layers.Dense(n_feat, activation=act, 
                         kernel_regularizer=reg, 
                         bias_regularizer=reg,
                         activity_regularizer=reg)(X)

    return dense

def max_pool(X):
    pool = layers.MaxPool2D((2,2), strides=2, padding='same')(X)
    return pool
   
#---------------------------------------------------------------------------------------------
inputs = tf.keras.Input(shape=(xdim,ydim,cdim))

conv1 = conv_set(inputs, 32, [3,3], 'tanh')
pool1 = max_pool(conv1)

conv2 = conv_set(pool1, 32, [3,3], 'tanh')
pool2 = max_pool(conv2)

conv3 = conv_set(pool2, 16, [3,3], 'tanh')
conv4 = conv_set(conv3, 16, [3,3], 'tanh')
conv5 = conv_set(conv4, 16, [3,3], 'tanh')

flat = layers.Flatten()(conv5)

dense1 = dense_set(flat, 32, 'sigmoid', reg='l2')

# output
outputs = dense_set(dense1, 1, None, reg='l2')

#---------------------------------------------------------------------------------------------
if op_train == 'on':

    # compile
    model = Model(inputs=inputs, outputs=outputs)
    model.compile(optimizer='adam', loss='mse')
    
    # run
    history = model.fit(tr_x, tr_y, batch_size=2048, epochs=800, verbose=0,
                        callbacks=callbacks_list,
                        validation_data=(val_x, val_y))

    model.save(o_path+'model_last.hdf5')

    history_dict = history.history
    tr_loss = history_dict['loss']

    # save the model summary, logs
    with open(o_path+'model_summary.md', 'w') as f:
        with redirect_stdout(f):
            model.summary()
        
    tr_loss = np.array(tr_loss)

    tr_loss.astype('float32').tofile(o_path+'tr_loss.gdat')

#---------------------------------------------------------------------------------------------
if op_test == 'on':

    # load model
    model = models.load_model(o_path+'model_last.hdf5')

    # prediction
    result = model.predict(test_x)
    result = np.array(result)

    result.astype('float32').tofile(o_path+'o_name.gdat')

    ctl = open(o_path+'o_name.ctl','w')
    ctl.write('dset ^o_name.gdat\n')
    ctl.write('undef -9.99e+08\n')
    ctl.write('xdef   1  linear   0.  2.5\n')
    ctl.write('ydef   1  linear -90.  2.5\n')
    ctl.write('zdef   1  linear 1 1\n')
    ctl.write('tdef '+str(test_tdim)+'  linear jan1980 1dy\n')
    ctl.write('vars   1\n')
    ctl.write('p    1   1  p\n')
    ctl.write('ENDVARS\n')
    ctl.close()

